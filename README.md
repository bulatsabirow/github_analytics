# GitHub API Parser + API application #

## Требования ##
1. [Python >= 3.10](https://www.python.org/downloads/)
2. [Poetry](https://pypi.org/project/poetry/)
3. [Yandex Cloud CLI](https://yandex.cloud/ru/docs/cli/quickstart#install)

---
Проект выполнен по следующему ТЗ:  
**API-приложение в docker на FastAPI.**  
RESTful API приложение должно быть обернуто в *docker compose*. 

**GET /api/repos/top100**

Отображение топ 100 публичных репозиториев. Топ составляется по количеству звезд (stars). 
Плюсом будет реализация сортировки по полям в виде параметров запроса. 
Схема (список объектов):
- repo: string – название репозитория (full_name в API GitHub)
- owner: string - владелец репозитория
- position_cur: integer – текущая позиция в топе
- position_prev: integer – предыдущая позиция в топе
- stars: integer – количество звёзд
- watchers: integers – количество просмотров
- forks: integer – количество форков
- open_issues: integer – количество открытых issues
- language: string - язык

**GET /api/repos/{owner}/{repo}/activity**  
Информация об активности репозитория по коммитам за выбранный промежуток времени по дням. 
Параметры запроса since и until для выбора промежутка дат.
Схема (список объектов):
- date: date
- commits: int – количество коммитов за конкретный день
- authors: list[string] – список разработчиков, которые выполняли коммиты 

**Парсер на данных с GitHub.**  
Периодический (интервал выбери сам с обоснованием) парсинг данных в PostgreSQL. 
Схемы таблиц в PostgreSQL должны соответствовать схемам эндпойнтов приложения. 
Реализация должна быть на базе тривиальной клауд функции Яндекс Облака (можно развернуть и протестировать на бесплатной версии Яндекс.Облака). 
По возможности все действия, необходимые для создания клауд функции и триггера, 
должны совершаться простым скриптом для Yandex Cloud CLI. 
Параметры подключения к PostgreSQL задаются в переменных окружения клауд функции.

---

## 1.API application ##
### Запуск проекта через Docker ###
`docker compose -f 'deploy/docker-compose.yml' up -d`

### Классический метод запуска проекта ###
1. Вход в виртуальное окружение:
    `
    poetry shell 
    `
2. Установка зависимостей:
    `
    poetry install
    `
3. Поднятие PostgreSQL с помощью Docker:
    `
    docker compose -f 'docker-compose.dev.yml' up -d
    `
4. Выполнение миграций:
    `
    alembic updrage head
    `
5. Инициализация линтера:
    `
    pre-commit install
    `
6. Запуск тестов:
    `
    pytest
    `
7. Запуск сервера для разработки на http://localhost:8000:
    `
    cd api && uvicorn main:app --reload
    `

---

## 2.GitHub API parser ##
### Запуск функции и триггера в Yandex Cloud ###
1. Убедиться, что определены следующие переменные окружения:
   * `$FOLDER_ID` - если не определен, 
   то выполнить команду в терминале: `yc resource-manager folder list` и 
   в выведенной таблице выбрать значение из столбца `id`. В случае отсутствия в выводе какого-либо `id`, выполнить такую команду:
   `
   yc resource-manager folder create \
   --name <new-folder>
   `
   * `$SERVICE_ACCOUNT_ID` - если не определен, 
   то выполнить команду в терминале: `yc iam service-account list` и
   аналогично выбрать значение. В случае отсутствия в выводе какого-либо `id`, выполнить такую команду:
   `
   yc iam service-account create \
   --name <service-account> \
   --description 'Github API parsing service account' \
   --format json
   `.
   * `$DB_NAME` - название базы данных (не СУБД).
   * `$DB_USER` - пользователь базы данных, от имени которого будет осуществлен доступ.
   * `$DB_PASSWORD` - пароль пользователя.
   * `$DB_HOST` - имя хоста, на котором размещена СУБД.
   * `$DB_PORT` - номер порта.
2. [Опционально] Создать или использовать уже готовый персональный токен GitHub для увеличения лимита запросов в час.
    Сохранить его значение в переменную окружения `$GITHUB_TOKEN`.
3. Запустить скрипт `yandex-cloud-function.sh`:
    `sh yandex-cloud-function.sh`, выполняющий следующие действия:
   1. Назначает роль `editor` сервисному аккаунту с `id`=`$SERVICE_ACCOUNT_ID`
      для обеспечения доступа к дальнейшим операциям.
   2. Определяет облачную функцию с именем `github-api-parser`.
   3. Запаковывает в архив `github_api_parser.zip` содержимое папки `scheduled_parser`.
   4. Создает новую версию облачной функции с необходимыми параметрами.
   5. Создает триггер для созданной функции, запускающий ее каждый час. Такой интервал
      обусловлен наличием у GitHub API лимита на количество запросов в час: 60 для не аутентифицированных 
      и 5000 для аутентифицированных.

---

## Обозначения символов в коммитах ##
- `+` - добавлено
- `-` - удалено
- `=` - изменено/улучшено
- `!` - исправлено